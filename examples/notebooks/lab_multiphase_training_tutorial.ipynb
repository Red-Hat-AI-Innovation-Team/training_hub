{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# LAB Multi-Phase Training with Training Hub\n\nThis notebook demonstrates how to perform LAB (Large-scale Alignment for chatBots) multi-phase training using the training_hub library. We'll walk through the two-phase LAB training process:\n\n1. **Phase 1 - Knowledge Tuning (Phase07)**: Training on knowledge-heavy data to build foundational understanding\n2. **Phase 2 - Skills + Replay Training (Phase10)**: Training on skills data with replay of both Phase07 knowledge data AND the base model's original instruction tuning data to maintain all capabilities\n\nThis LAB multi-phase approach is specifically designed for instruction tuning where you first establish additional knowledge foundations, then add task-specific skills while preventing knowledge forgetting and preserving the base model's original instruction-following capabilities through comprehensive replay mechanisms."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our training environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import training_hub for SFT training\nfrom training_hub import sft\n\n# Standard library imports\nimport os\nimport time\nfrom datetime import datetime"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Let's define our training configuration. You'll need to adjust these paths to match your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# LAB Multi-Phase Training Configuration\nexperiment_prefix = \"lab_multiphase_training_demo\"\nckpt_output_base_dir = \"/path/to/your/checkpoints\"  # Update this path\n\n# Model and data paths - Update these to your actual paths\nbase_model_path = \"/path/to/your/base/model\"  # e.g., granite-3.1-8b-starter-v2.1\nphase07_data_path = \"/path/to/knowledge_data.jsonl\"  # Knowledge/facts data for Phase07\nphase10_data_path = \"/path/to/skills_plus_replay_data.jsonl\"  # Skills + replay data for Phase10\n# Note: Phase10 data should include:\n# - New skills/task data\n# - Replay of Phase07 knowledge data  \n# - Replay of base model's original instruction tuning data\n\n# Training hyperparameters\nmax_tokens_per_gpu = 45_000  # Memory limit per GPU\nmax_seq_len = 40_000         # Maximum sequence length\n\n# Distributed training setup (adjust for your hardware)\nnproc_per_node = 8  # Number of GPUs per node\nnnodes = 1          # Number of nodes\nnode_rank = 0       # This node's rank\nrdzv_id = 420       # Rendezvous ID\nrdzv_endpoint = \"0.0.0.0:12345\"  # Master endpoint\n\nprint(f\"LAB Multi-Phase Experiment: {experiment_prefix}\")\nprint(f\"Output directory: {ckpt_output_base_dir}\")\nprint(f\"GPUs per node: {nproc_per_node}\")\nprint(f\"Max tokens per GPU: {max_tokens_per_gpu:,}\")\nprint(f\"\\nData composition:\")\nprint(f\"  Phase07: Knowledge data only\")\nprint(f\"  Phase10: Skills + Phase07 replay + Base model instruction replay\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Phase 1: Knowledge Tuning (Phase07)\n\nIn Phase07, we train the model on knowledge-heavy data to establish foundational understanding. This phase focuses on factual information, domain knowledge, and core concepts that the model needs to master before learning specific skills."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Phase07 (Knowledge Tuning) configuration\nexperiment_prefix_phase07 = experiment_prefix + \"_phase07\"\nexperiment_name_phase07 = experiment_prefix_phase07 + \"_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nphase07_ckpt_output_dir = os.path.join(ckpt_output_base_dir, experiment_prefix_phase07)\n\nprint(f\"Phase07 (Knowledge Tuning) Configuration:\")\nprint(f\"  Experiment name: {experiment_name_phase07}\")\nprint(f\"  Input model: {base_model_path}\")\nprint(f\"  Data path: {phase07_data_path}\")\nprint(f\"  Output directory: {phase07_ckpt_output_dir}\")\nprint(f\"  Training on knowledge data...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run Phase07 training\nprint(\"üöÄ Starting Phase07 (Knowledge Tuning) Training...\")\nstart_time = time.time()\n\ntry:\n    sft(\n        # Required parameters\n        model_path=base_model_path,           # Path to the model to fine-tune\n        data_path=phase07_data_path,          # Path to the training data\n        ckpt_output_dir=phase07_ckpt_output_dir,  # Directory to save checkpoints\n        \n        # Core training parameters\n        num_epochs=7,                         # Number of training epochs\n        effective_batch_size=128,             # Effective batch size for training (smaller due to smaller knowledge dataset)\n        learning_rate=2e-5,                   # Learning rate for training\n        max_seq_len=max_seq_len,              # Maximum sequence length\n        max_tokens_per_gpu=max_tokens_per_gpu, # Maximum tokens per GPU in a mini-batch (hard-cap for memory to avoid OOMs)\n        \n        # Data and checkpointing parameters\n        data_output_dir=\"/dev/shm\",           # Directory to save processed data (using RAM for faster data processing)\n        warmup_steps=0,                       # Number of warmup steps\n        save_samples=0,                       # Number of samples to save after training (0 disables saving based on sample count)\n        checkpoint_at_epoch=True,             # Whether to checkpoint at each epoch (default value, shown for clarity)\n        accelerate_full_state_at_epoch=False, # Whether to save full state at epoch for automatic checkpoint resumption (override default to save space)\n        \n        # Distributed training parameters\n        nproc_per_node=nproc_per_node,        # Number of processes (GPUs) per node for distributed training\n        nnodes=nnodes,                        # Total number of nodes for distributed training\n        node_rank=node_rank,                  # Rank of this node (0 to nnodes-1) for distributed training\n        rdzv_id=rdzv_id,                      # Unique job ID for rendezvous in distributed training\n        rdzv_endpoint=rdzv_endpoint,          # Master node endpoint for multi-node training\n    )\n    \n    end_time = time.time()\n    duration = end_time - start_time\n    print(f\"‚úÖ Phase07 (Knowledge Tuning) completed successfully in {duration/3600:.2f} hours\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Phase07 (Knowledge Tuning) failed: {e}\")\n    raise"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Checkpoint Discovery\n\nAfter Phase07 completes, we need to find the most recent checkpoint to use as input for Phase10."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Find the most recent checkpoint from Phase07\nphase07_checkpoint_location = f\"{phase07_ckpt_output_dir}/hf_format\"\n\nprint(f\"Looking for Phase07 checkpoints in: {phase07_checkpoint_location}\")\n\nif not os.path.exists(phase07_checkpoint_location):\n    print(f\"‚ùå Checkpoint directory not found: {phase07_checkpoint_location}\")\n    print(\"   Make sure Phase07 completed successfully\")\nelse:\n    phase07_checkpoints = os.listdir(phase07_checkpoint_location)\n    \n    if not phase07_checkpoints:\n        print(f\"‚ùå No checkpoints found in {phase07_checkpoint_location}\")\n    else:\n        print(f\"Found {len(phase07_checkpoints)} checkpoint(s):\")\n        for ckpt in phase07_checkpoints:\n            print(f\"  - {ckpt}\")\n        \n        # Find the most recent checkpoint\n        most_recent_checkpoint, most_recent_time = None, 0\n        \n        for checkpoint in phase07_checkpoints:\n            full_ckpt_path = f\"{phase07_checkpoint_location}/{checkpoint}\"\n            if os.path.isdir(full_ckpt_path):\n                ckpt_time = os.stat(full_ckpt_path).st_ctime\n                if ckpt_time > most_recent_time:\n                    most_recent_checkpoint = full_ckpt_path\n                    most_recent_time = ckpt_time\n        \n        if most_recent_checkpoint:\n            print(f\"\\n‚úÖ Most recent Phase07 checkpoint: {most_recent_checkpoint}\")\n            print(f\"   Created: {datetime.fromtimestamp(most_recent_time)}\")\n        else:\n            print(\"‚ùå No valid checkpoint directories found\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Phase 2: Skills + Replay Training (Phase10)\n\nIn Phase10, we continue training from the Phase07 checkpoint using a comprehensive dataset that includes:\n\n1. **New Skills Data**: Task instructions, problem-solving examples, and specific capabilities\n2. **Phase07 Knowledge Replay**: Replay of the knowledge data from Phase07 to prevent knowledge forgetting  \n3. **Base Model Instruction Replay**: Replay of the base model's original instruction tuning data to preserve foundational instruction-following capabilities\n\nThis comprehensive replay strategy ensures that the model maintains both its original instruction-following abilities and the newly acquired knowledge from Phase07, while learning new skills in Phase10."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Phase10 (Skills + Replay Training) configuration\nif 'most_recent_checkpoint' not in locals() or most_recent_checkpoint is None:\n    print(\"‚ùå Cannot proceed with Phase10: No checkpoint from Phase07\")\n    print(\"   Please ensure Phase07 completed successfully\")\nelse:\n    phase10_input_model = most_recent_checkpoint\n    experiment_prefix_phase10 = experiment_prefix + \"_phase10\"\n    experiment_name_phase10 = experiment_prefix_phase10 + \"_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    phase10_ckpt_output_dir = os.path.join(ckpt_output_base_dir, experiment_prefix_phase10)\n    \n    print(f\"Phase10 (Skills + Replay Training) Configuration:\")\n    print(f\"  Experiment name: {experiment_name_phase10}\")\n    print(f\"  Input model (from Phase07): {phase10_input_model}\")\n    print(f\"  Data path: {phase10_data_path}\")\n    print(f\"  Output directory: {phase10_ckpt_output_dir}\")\n    print(f\"  Training on skills + comprehensive replay data...\")\n    print(f\"  ‚Ü≥ Skills data + Phase07 knowledge replay + Base model instruction replay\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run Phase10 training\nif 'phase10_input_model' in locals():\n    print(\"üöÄ Starting Phase10 (Skills + Replay Training)...\")\n    start_time = time.time()\n    \n    try:\n        sft(\n            # Required parameters\n            model_path=phase10_input_model,       # Path to the model to fine-tune (from Phase07 checkpoint)\n            data_path=phase10_data_path,          # Path to the training data (skills + replay data)\n            ckpt_output_dir=phase10_ckpt_output_dir,  # Directory to save checkpoints\n            \n            # Core training parameters\n            num_epochs=7,                         # Number of training epochs\n            effective_batch_size=3840,            # Effective batch size for training (larger due to larger skills + replay dataset)\n            learning_rate=2e-5,                   # Learning rate for training\n            max_seq_len=max_seq_len,              # Maximum sequence length\n            max_tokens_per_gpu=max_tokens_per_gpu, # Maximum tokens per GPU in a mini-batch (hard-cap for memory to avoid OOMs)\n            \n            # Data and checkpointing parameters\n            data_output_dir=\"/dev/shm\",           # Directory to save processed data (using RAM for faster data processing)\n            warmup_steps=0,                       # Number of warmup steps\n            save_samples=0,                       # Number of samples to save after training (0 disables saving based on sample count)\n            checkpoint_at_epoch=True,             # Whether to checkpoint at each epoch (default value, shown for clarity)\n            accelerate_full_state_at_epoch=True,  # Whether to save full state at epoch for automatic checkpoint resumption (default value, enable for final model)\n            \n            # Distributed training parameters\n            nproc_per_node=nproc_per_node,        # Number of processes (GPUs) per node for distributed training\n            nnodes=nnodes,                        # Total number of nodes for distributed training\n            node_rank=node_rank,                  # Rank of this node (0 to nnodes-1) for distributed training\n            rdzv_id=rdzv_id,                      # Unique job ID for rendezvous in distributed training\n            rdzv_endpoint=rdzv_endpoint,          # Master node endpoint for multi-node training\n        )\n        \n        end_time = time.time()\n        duration = end_time - start_time\n        print(f\"‚úÖ Phase10 (Skills + Replay Training) completed successfully in {duration/3600:.2f} hours\")\n        \n    except Exception as e:\n        print(f\"‚ùå Phase10 (Skills + Replay Training) failed: {e}\")\n        raise\nelse:\n    print(\"‚è≠Ô∏è Skipping Phase10 due to missing Phase07 checkpoint\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Summary\n",
    "\n",
    "Let's summarize what we accomplished and where to find the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"üéâ LAB Multi-Phase Training Summary\")\nprint(\"=\" * 50)\n\nif 'phase07_ckpt_output_dir' in locals():\n    print(f\"üìÅ Phase07 (Knowledge Tuning) Output: {phase07_ckpt_output_dir}\")\n    \nif 'phase10_ckpt_output_dir' in locals():\n    print(f\"üìÅ Phase10 (Skills + Replay) Output: {phase10_ckpt_output_dir}\")\n    print(f\"\\nüéØ Final trained model location:\")\n    print(f\"   {phase10_ckpt_output_dir}/hf_format/[latest_checkpoint]\")\n    \n    # List final checkpoints if available\n    final_ckpt_dir = f\"{phase10_ckpt_output_dir}/hf_format\"\n    if os.path.exists(final_ckpt_dir):\n        final_checkpoints = [d for d in os.listdir(final_ckpt_dir) if os.path.isdir(os.path.join(final_ckpt_dir, d))]\n        if final_checkpoints:\n            print(f\"\\nüìã Available final checkpoints:\")\n            for ckpt in sorted(final_checkpoints):\n                print(f\"   - {ckpt}\")\n\nprint(f\"\\nüîß LAB Training Configuration Used:\")\nprint(f\"   - Max tokens per GPU: {max_tokens_per_gpu:,}\")\nprint(f\"   - Max sequence length: {max_seq_len:,}\")\nprint(f\"   - GPUs per node: {nproc_per_node}\")\nprint(f\"   - Phase07 batch size: 128 (smaller knowledge dataset)\")\nprint(f\"   - Phase10 batch size: 3840 (larger skills + replay dataset)\")\nprint(f\"   - Learning rate: 2e-5\")\nprint(f\"   - Epochs per phase: 7\")\n\nprint(f\"\\nüìä Data Composition:\")\nprint(f\"   - Phase07: Knowledge data only\")\nprint(f\"   - Phase10: Skills + Phase07 replay + Base model instruction replay\")\n\nprint(f\"\\nüí° Next Steps:\")\nprint(f\"   1. Evaluate your model on relevant benchmarks\")\nprint(f\"   2. Test with sample prompts to verify training quality\")\nprint(f\"   3. Check knowledge retention from Phase07\")\nprint(f\"   4. Verify new skills acquisition from Phase10\")\nprint(f\"   5. Confirm base model instruction-following capabilities are preserved\")\nprint(f\"   6. Deploy for inference using your preferred serving framework\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Key Concepts Explained\n\n### LAB Multi-Phase Training Benefits:\n\n1. **Knowledge ‚Üí Skills + Comprehensive Replay**: Phase07 builds foundational knowledge, Phase10 adds task-specific capabilities while replaying both Phase07 knowledge AND base model instruction data\n2. **Comprehensive Replay Strategy**: Prevents both knowledge forgetting (Phase07) and capability regression (base model instruction-following)\n3. **Dataset-Appropriate Batch Sizes**: Smaller batch size for smaller knowledge datasets, larger batch size for larger skills + replay datasets\n4. **Checkpoint Continuity**: Seamlessly continue from Phase07 results into Phase10\n5. **Multi-Level Preservation**: Maintains original instruction capabilities, Phase07 knowledge, and adds new Phase10 skills\n\n### Training_Hub Advantages:\n\n1. **Simplified Interface**: Single `sft()` function instead of separate argument objects\n2. **Clear Parameter Organization**: Logical grouping of training, distributed, and advanced options\n3. **Backend Flexibility**: Easy to switch between different training backends\n4. **Better Documentation**: Clear parameter names like `max_tokens_per_gpu`\n\n### LAB Training Strategy:\n\n- **Phase07 Focus**: Knowledge acquisition on typically smaller, focused knowledge datasets\n- **Phase10 Focus**: Skills training with comprehensive replay on larger combined datasets\n- **Dual Replay Mechanism**: Prevents both knowledge drift and instruction capability loss\n- **Memory Management**: `max_tokens_per_gpu` prevents OOM while maintaining throughput\n- **Fast Data Loading**: Using `/dev/shm` for data processing\n- **Checkpointing Strategy**: Different strategies for intermediate vs final models\n\n### Data Composition Details:\n\n**Phase07**: Pure knowledge data for focused learning (typically smaller datasets)\n**Phase10**: Carefully balanced mixture of (typically much larger combined dataset):\n- New skills/task data (primary learning objective)\n- Phase07 knowledge replay (prevents knowledge forgetting)\n- Base model instruction replay (preserves original capabilities)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "1. **Out of Memory (OOM)**:\n",
    "   - Reduce `max_tokens_per_gpu`\n",
    "   - Reduce `effective_batch_size`\n",
    "   - Check GPU memory usage\n",
    "\n",
    "2. **Checkpoint Not Found**:\n",
    "   - Verify Phase 1 completed successfully\n",
    "   - Check `ckpt_output_dir` permissions\n",
    "   - Look for error messages in training logs\n",
    "\n",
    "3. **Distributed Training Issues**:\n",
    "   - Verify network connectivity between nodes\n",
    "   - Check `rdzv_endpoint` accessibility\n",
    "   - Ensure consistent environment across nodes\n",
    "\n",
    "4. **Data Loading Errors**:\n",
    "   - Verify data file paths exist\n",
    "   - Check JSONL format validity\n",
    "   - Ensure sufficient disk space in `/dev/shm`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}